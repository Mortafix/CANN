{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK with K-MEANS for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "from random import randint\n",
    "from scipy import misc\n",
    "from scipy import special\n",
    "import scipy.ndimage\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import collections\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN = 'data_training'\n",
    "IMAGES_TEST = 'data_testing'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = DATA_PATH+IMAGES_TRAIN\n",
    "data_testing = DATA_PATH+IMAGES_TEST\n",
    "ft = gzip.open(data_training, 'rb')\n",
    "TRAINING = pickle.load(ft)\n",
    "ft.close()\n",
    "ft = gzip.open(data_testing, 'rb')\n",
    "TESTING = pickle.load(ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    \n",
    "    def __init__(self, neurons, batchsize, stop_function, stop_parameter):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        \n",
    "        # Standardize random weights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = np.random.rand(self.neurons, self.input_size + 1) / self.neurons\n",
    "        output_layer = np.random.rand(self.output_size, self.neurons + 1) / self.output_size\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nBatch Train: %d\\nBatch Test: %d\\n%s\\n' % (self.neurons,len_batch_train,len_batch_test,typeTrainingPrint))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "\n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backpropagate(input_vector, target_vector)\n",
    "            \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        # Print last epoch\n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target):\n",
    "        c = 1./math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], 300, 1).T, output_deltas)\n",
    "        self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "\n",
    "    def accu(self, testing):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-11-21 17:08:48.654417) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000\n",
      "Batch Test: 10000\n",
      "Stop Function: 3 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (38s)    Accuracy: 81.26%\tMin: 1.57% (5)\n",
      "Epoch 010 (6m16s)  Accuracy: 96.38%\tMin: 93.95% (6)\n",
      "Epoch 014 (8m44s)  Accuracy: 96.53%\tMin: 94.46% (8)\n",
      "\n",
      "-- Training Session End (2018-11-21 17:17:33.254539) --\n"
     ]
    }
   ],
   "source": [
    "nn = Neural_Network(neurons=300,batchsize=1,stop_function=1,stop_parameter=3)\n",
    "nn.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_centroid_index(centers,value):\n",
    "    centers = np.asarray(centers)\n",
    "    idx = (np.abs(centers - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clusters(cluster,weights):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=cluster,random_state=RANDOM_SEED)\n",
    "    kmeans.fit(np.hstack(weights).reshape(-1,1))\n",
    "    return kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix (Helper Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_weights(weights,centers):\n",
    "    arr_ret = np.empty_like(weights).astype(np.int16)\n",
    "    for i, row in enumerate(weights):\n",
    "        for j, col in enumerate(row):\n",
    "            arr_ret[i,j] = nearest_centroid_index(centers,weights[i,j])\n",
    "    return arr_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_matrix_to_matrix(idx_matrix,centers,shape):\n",
    "    return centers[idx_matrix.reshape(-1,1)].reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_gradient_matrix(idx_matrix,gradient,cluster):\n",
    "    return scipy.ndimage.sum(gradient,idx_matrix,index=range(cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_KM:\n",
    "\n",
    "    def __init__(self, neurons, batchsize, cluster, pre_weights, stop_function, stop_parameter):\n",
    "        \n",
    "        start_setting_time = dt.datetime.now()\n",
    "        \n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.cluster = cluster\n",
    "        self.iteration = 0\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        \n",
    "        # Variable for shape\n",
    "        shape_hidden = (self.neurons,self.input_size+1)\n",
    "        shape_output = (self.output_size,self.neurons+1)\n",
    "        self.layers_shape = [shape_hidden,shape_output]\n",
    "            \n",
    "        # Initialize cluster for pre-trained weights (dict with centers)\n",
    "        c_hidden = build_clusters(self.cluster,pre_weights[0])\n",
    "        c_output = build_clusters(self.cluster,pre_weights[-1])\n",
    "        self.centers = [c_hidden,c_output]\n",
    "        \n",
    "        # Initialize index matrix for pre-trained weights\n",
    "        idx_hidden = redefine_weights(pre_weights[0],self.centers[0])\n",
    "        idx_output = redefine_weights(pre_weights[-1],self.centers[-1])\n",
    "        self.idx_layers = [idx_hidden,idx_output]\n",
    "        \n",
    "        # Setting time print    \n",
    "        end_setting_time = dt.datetime.now() - start_setting_time\n",
    "        eta = divmod(end_setting_time.days * 86400 + end_setting_time.seconds, 60)\n",
    "        self.eta_print_setting = str(eta[0])+\"m\"+str(eta[1])+\"s\"\n",
    "    \n",
    " \n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nClusters: %d\\nBatch Train: %d\\nBatch Test: %d\\n%s\\n' % (self.neurons,self.cluster,len_batch_train,len_batch_test,typeTrainingPrint))\n",
    "        \n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            \n",
    "            # Backpropagate with feed forward\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                weights = []\n",
    "                for i,c,s in zip(self.idx_layers,self.centers,self.layers_shape):\n",
    "                    w = idx_matrix_to_matrix(i,c,s)\n",
    "                    weights.append(w)\n",
    "                self.backpropagate(input_vector, target_vector, weights)\n",
    "                \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output,weights)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                      \n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector, weights):\n",
    "        outputs = []\n",
    "        for w in weights:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(w, input_with_bias)\n",
    "            output = special.expit(output) # Sigmoid function\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target, weights):\n",
    "        c = 1./math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector, weights)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        gradient = np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        cg = centroid_gradient_matrix(self.idx_layers[-1],gradient,self.cluster)\n",
    "        self.centers[-1] = self.centers[-1] - c * np.array(cg).reshape(self.cluster,1)\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(weights[-1], 300, 1).T, output_deltas)\n",
    "        gradient = np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "        cg = centroid_gradient_matrix(self.idx_layers[0],gradient,self.cluster)\n",
    "        self.centers[0] = self.centers[0] - c * np.array(cg).reshape(self.cluster,1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self, input_vector, weights):\n",
    "        return self.feed_forward(input_vector,weights)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector, weights):\n",
    "        return np.argmax(self.feed_forward(input_vector,weights)[-1])\n",
    "\n",
    "    def accu(self, testing, weights):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k], weights) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers\n",
    "    \n",
    "    def minsec2sec(self,time):\n",
    "        if 'm' in time:\n",
    "            splitted = time.split('m')\n",
    "            return int(splitted[0]) * 60 + int(splitted[1][:-1])\n",
    "        else:\n",
    "            return int(time[:-1])\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-11-18 15:41:50.323669) --\n",
      "\n",
      "Neurons: 300\n",
      "Clusters: 256\n",
      "Batch Train: 60000\n",
      "Batch Test: 10000\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (2m49s)  Accuracy: 96.68%\tMin: 94.09% (2)\n",
      "Epoch 002 (5m39s)  Accuracy: 96.74%\tMin: 93.12% (8)\n",
      "Epoch 003 (8m27s)  Accuracy: 96.87%\tMin: 94.35% (9)\n",
      "Epoch 004 (11m15s) Accuracy: 96.58%\tMin: 94.85% (9)\n",
      "Epoch 005 (14m4s)  Accuracy: 97.01%\tMin: 95.04% (9)\n",
      "Epoch 006 (16m56s) Accuracy: 96.74%\tMin: 94.67% (2)\n",
      "Epoch 007 (19m46s) Accuracy: 96.81%\tMin: 94.17% (5)\n",
      "\n",
      "-- Training Session End (2018-11-18 16:01:36.896155) --\n"
     ]
    }
   ],
   "source": [
    "pre_trained_weights = nn.getWeights()\n",
    "nn_km = Neural_Network_KM(neurons=300,batchsize=1,cluster=256,pre_weights=pre_trained_weights,stop_function=1,stop_parameter=2)\n",
    "nn_km.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_matrix(mat,percentage,method='out'):\n",
    "    threshold = (100-percentage)\n",
    "    \n",
    "    if method == 'inout':\n",
    "        threshold /= 4\n",
    "        perc_up,perc_down,perc_mid_up,perc_mid_down = 100 - threshold, threshold, 50 + threshold, 50 - threshold\n",
    "        percentile_up = np.percentile(mat,perc_up)\n",
    "        percentile_down = np.percentile(mat,perc_down)\n",
    "        percentile_mid_up = np.percentile(mat,perc_mid_up)\n",
    "        percentile_mid_down = np.percentile(mat,perc_mid_down)\n",
    "    else:\n",
    "        threshold /= 2\n",
    "        if method == 'in': perc_up, perc_down = 50 + threshold, 50 - threshold\n",
    "        elif method == 'out': perc_up, perc_down = 100 - threshold, threshold\n",
    "        percentile_up = np.percentile(mat,perc_up)\n",
    "        percentile_down = np.percentile(mat,perc_down)\n",
    "        \n",
    "    w_pruned = np.copy(mat)\n",
    "    for i,row in enumerate(mat):\n",
    "        for j,_ in enumerate(row):\n",
    "            if method == 'in':\n",
    "                if mat[i,j] > percentile_down and mat[i,j] < percentile_up:\n",
    "                    w_pruned[i,j] = 0\n",
    "            elif method == 'out':\n",
    "                if mat[i,j] < percentile_down or mat[i,j] > percentile_up:\n",
    "                    w_pruned[i,j] = 0\n",
    "            elif method == 'inout':\n",
    "                if mat[i,j] < percentile_down or mat[i,j] > percentile_up or (mat[i,j] > percentile_mid_down and mat[i,j] < percentile_mid_up):\n",
    "                    w_pruned[i,j] = 0\n",
    "    return csr_matrix(w_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_build_clusters(cluster,weights):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=cluster,random_state=RANDOM_SEED)\n",
    "    kmeans.fit(weights.data.reshape(-1,1))\n",
    "    return kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_redefine_weights(weights,centers):\n",
    "    csr_idx = weights.copy()\n",
    "    arr_ret = np.empty_like(csr_idx.data).astype(np.int16)\n",
    "    for i,w in enumerate(csr_idx.data):\n",
    "        arr_ret[i] = nearest_centroid_index(centers,w)\n",
    "    csr_idx.data = arr_ret\n",
    "    return csr_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_idx_matrix_to_matrix(idx_matrix,centers):\n",
    "    w_csr = idx_matrix.copy()\n",
    "    w_csr.data = centers[w_csr.data]\n",
    "    return w_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_centroid_gradient_matrix(idx_matrix,gradient,cluster):\n",
    "    return scipy.ndimage.sum(gradient,idx_matrix.todense(),index=range(cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Pruning and K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_PR_KM:\n",
    "\n",
    "    def __init__(self, neurons, batchsize, cluster, pre_weights, pruning, pruning_method, stop_function, stop_parameter):\n",
    "        \n",
    "        start_setting_time = dt.datetime.now()\n",
    "        \n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.pruning = pruning\n",
    "        self.pruning_method = pruning_method\n",
    "        self.cluster = cluster\n",
    "        self.iteration = 0\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        \n",
    "        # Pruning weights\n",
    "        pw_hidden = pruning_matrix(pre_weights[0],self.pruning,self.pruning_method)\n",
    "        pw_output = pruning_matrix(pre_weights[1],self.pruning,self.pruning_method)\n",
    "        self.pruned_weights = [pw_hidden,pw_output]\n",
    "        \n",
    "        # Variable for shape\n",
    "        shape_hidden = (self.neurons,self.input_size+1)\n",
    "        shape_output = (self.output_size,self.neurons+1)\n",
    "        self.layers_shape = [shape_hidden,shape_output]\n",
    "            \n",
    "        # Initialize cluster for pre-trained weights pruned\n",
    "        c_hidden = P_build_clusters(self.cluster,self.pruned_weights[0])\n",
    "        c_output = P_build_clusters(self.cluster,self.pruned_weights[-1])\n",
    "        self.centers = [c_hidden,c_output]\n",
    "        \n",
    "        # Initialize index matrix for pre-trained weights\n",
    "        idx_hidden = P_redefine_weights(self.pruned_weights[0],self.centers[0])\n",
    "        idx_output = P_redefine_weights(self.pruned_weights[-1],self.centers[-1])\n",
    "        self.idx_layers = [idx_hidden,idx_output]\n",
    "        \n",
    "        # Setting time print    \n",
    "        end_setting_time = dt.datetime.now() - start_setting_time\n",
    "        eta = divmod(end_setting_time.days * 86400 + end_setting_time.seconds, 60)\n",
    "        self.eta_print_setting = str(eta[0])+\"m\"+str(eta[1])+\"s\"\n",
    "    \n",
    " \n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nBatch Train: %d (%d%%)\\nBatch Test: %d (%d%%)\\nClusters: %d\\nPruning: %d%% (%s)\\n%s\\n' % (self.neurons,len_batch_train,self.batchsize*100,len_batch_test,self.batchsize*100,self.cluster,self.pruning,self.pruning_method,typeTrainingPrint))\n",
    "        \n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            \n",
    "            # Backpropagate with feed forward\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                weights = []\n",
    "                for i,c in zip(self.idx_layers,self.centers):\n",
    "                    w = P_idx_matrix_to_matrix(i,c)\n",
    "                    weights.append(w)\n",
    "                self.backpropagate(input_vector, target_vector, weights)\n",
    "                \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output,weights)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                      \n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector, weights):\n",
    "        outputs = []\n",
    "        for w in weights:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(w.toarray(), input_with_bias)\n",
    "            output = special.expit(output) # Sigmoid function\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target, weights):\n",
    "        c = 1./math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector, weights)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        gradient = np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        cg = P_centroid_gradient_matrix(self.idx_layers[-1],gradient,self.cluster)\n",
    "        self.centers[-1] = self.centers[-1] - c * np.array(cg).reshape(self.cluster,1)\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        cleared_bias = np.delete(weights[-1].toarray(),300,1).T #np.delete(weights[-1], 300, 1).T\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(cleared_bias, output_deltas)\n",
    "        gradient = np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "        cg = P_centroid_gradient_matrix(self.idx_layers[0],gradient,self.cluster)\n",
    "        self.centers[0] = self.centers[0] - c * np.array(cg).reshape(self.cluster,1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self, input_vector, weights):\n",
    "        return self.feed_forward(input_vector,weights)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector, weights):\n",
    "        return np.argmax(self.feed_forward(input_vector,weights)[-1])\n",
    "\n",
    "    def accu(self, testing, weights):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k], weights) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers\n",
    "    \n",
    "    def minsec2sec(self,time):\n",
    "        if 'm' in time:\n",
    "            splitted = time.split('m')\n",
    "            return int(splitted[0]) * 60 + int(splitted[1][:-1])\n",
    "        else:\n",
    "            return int(time[:-1])\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-11-19 19:48:24.029130) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 50% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (3m39s)  Accuracy: 76.8%\tMin: 62.11% (5)\n",
      "Epoch 002 (7m19s)  Accuracy: 77.48%\tMin: 61.66% (5)\n",
      "Epoch 003 (10m59s) Accuracy: 78.01%\tMin: 63.57% (5)\n",
      "Epoch 004 (14m39s) Accuracy: 78.91%\tMin: 65.58% (5)\n",
      "Epoch 005 (18m18s) Accuracy: 79.02%\tMin: 66.14% (5)\n",
      "Epoch 006 (21m58s) Accuracy: 79.34%\tMin: 66.82% (5)\n",
      "Epoch 007 (25m38s) Accuracy: 79.25%\tMin: 67.04% (5)\n",
      "Epoch 008 (29m18s) Accuracy: 79.48%\tMin: 68.39% (5)\n",
      "Epoch 009 (32m58s) Accuracy: 79.48%\tMin: 67.71% (5)\n",
      "Epoch 010 (36m37s) Accuracy: 79.51%\tMin: 68.05% (5)\n",
      "Epoch 011 (40m17s) Accuracy: 79.5%\tMin: 67.38% (5)\n",
      "Epoch 012 (43m57s) Accuracy: 79.49%\tMin: 68.5% (5)\n",
      "\n",
      "-- Training Session End (2018-11-19 20:32:21.612220) --\n",
      "-- Training Session Start (2018-11-19 20:32:26.923815) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 60% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (3m52s)  Accuracy: 81.12%\tMin: 66.48% (5)\n",
      "Epoch 002 (7m45s)  Accuracy: 81.56%\tMin: 61.1% (5)\n",
      "Epoch 003 (11m38s) Accuracy: 82.5%\tMin: 67.49% (5)\n",
      "Epoch 004 (15m30s) Accuracy: 82.86%\tMin: 69.96% (5)\n",
      "Epoch 005 (19m23s) Accuracy: 83.0%\tMin: 71.61% (2)\n",
      "Epoch 006 (23m16s) Accuracy: 83.1%\tMin: 71.61% (2)\n",
      "Epoch 007 (27m8s)  Accuracy: 83.43%\tMin: 71.46% (8)\n",
      "Epoch 008 (31m1s)  Accuracy: 83.06%\tMin: 72.67% (2)\n",
      "Epoch 009 (34m54s) Accuracy: 81.82%\tMin: 73.65% (5)\n",
      "\n",
      "-- Training Session End (2018-11-19 21:07:21.029564) --\n",
      "-- Training Session Start (2018-11-19 21:07:22.737573) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 70% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (3m56s)  Accuracy: 74.04%\tMin: 46.48% (9)\n",
      "Epoch 002 (7m52s)  Accuracy: 78.24%\tMin: 56.95% (5)\n",
      "Epoch 003 (11m47s) Accuracy: 77.99%\tMin: 63.9% (5)\n",
      "Epoch 004 (15m43s) Accuracy: 78.25%\tMin: 60.09% (5)\n",
      "Epoch 005 (19m38s) Accuracy: 79.19%\tMin: 64.35% (5)\n",
      "Epoch 006 (23m34s) Accuracy: 42.85%\tMin: 00.0% (8)\n",
      "Epoch 007 (27m29s) Accuracy: 44.62%\tMin: 00.0% (7)\n",
      "\n",
      "-- Training Session End (2018-11-19 21:34:52.359848) --\n",
      "-- Training Session Start (2018-11-19 21:34:58.714776) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 80% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (4m23s)  Accuracy: 17.39%\tMin: 00.0% (2)\n",
      "Epoch 002 (8m47s)  Accuracy: 17.41%\tMin: 00.0% (2)\n",
      "Epoch 003 (13m10s) Accuracy: 17.46%\tMin: 00.0% (2)\n",
      "Epoch 004 (17m34s) Accuracy: 17.46%\tMin: 00.0% (2)\n",
      "Epoch 005 (21m57s) Accuracy: 17.48%\tMin: 00.0% (2)\n",
      "Epoch 006 (26m21s) Accuracy: 17.51%\tMin: 00.0% (2)\n",
      "Epoch 007 (30m44s) Accuracy: 17.54%\tMin: 00.0% (2)\n",
      "Epoch 008 (35m8s)  Accuracy: 17.62%\tMin: 00.0% (2)\n",
      "Epoch 009 (39m32s) Accuracy: 17.67%\tMin: 00.0% (2)\n",
      "Epoch 010 (43m55s) Accuracy: 17.7%\tMin: 00.0% (2)\n",
      "Epoch 011 (48m19s) Accuracy: 17.74%\tMin: 00.0% (2)\n",
      "Epoch 012 (52m42s) Accuracy: 17.69%\tMin: 00.0% (2)\n",
      "Epoch 013 (57m6s)  Accuracy: 17.67%\tMin: 00.0% (2)\n",
      "\n",
      "-- Training Session End (2018-11-19 22:32:05.245747) --\n",
      "-- Training Session Start (2018-11-19 22:32:13.503605) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 90% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (4m15s)  Accuracy: 15.06%\tMin: 00.0% (2)\n",
      "Epoch 002 (8m30s)  Accuracy: 15.06%\tMin: 00.0% (2)\n",
      "Epoch 003 (12m45s) Accuracy: 15.06%\tMin: 00.0% (2)\n",
      "\n",
      "-- Training Session End (2018-11-19 22:44:59.372579) --\n",
      "-- Training Session Start (2018-11-19 22:45:01.536452) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Clusters: 256\n",
      "Pruning: 95% (out)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (4m13s)  Accuracy: 64.44%\tMin: 00.0% (8)\n",
      "Epoch 002 (8m27s)  Accuracy: 66.22%\tMin: 00.0% (8)\n",
      "Epoch 003 (12m40s) Accuracy: 68.32%\tMin: 00.0% (8)\n",
      "Epoch 004 (16m54s) Accuracy: 67.76%\tMin: 00.0% (8)\n",
      "Epoch 005 (21m8s)  Accuracy: 69.68%\tMin: 00.0% (8)\n",
      "Epoch 006 (25m21s) Accuracy: 65.8%\tMin: 00.0% (8)\n",
      "Epoch 007 (29m35s) Accuracy: 70.07%\tMin: 00.0% (8)\n",
      "Epoch 008 (33m51s) Accuracy: 69.97%\tMin: 00.0% (8)\n",
      "Epoch 009 (38m9s)  Accuracy: 70.55%\tMin: 00.0% (8)\n",
      "Epoch 010 (42m27s) Accuracy: 69.95%\tMin: 00.0% (8)\n",
      "Epoch 011 (46m43s) Accuracy: 69.75%\tMin: 00.0% (8)\n",
      "\n",
      "-- Training Session End (2018-11-19 23:31:45.301408) --\n"
     ]
    }
   ],
   "source": [
    "pre_trained_weights = nn.getWeights()\n",
    "for i in [50,60,70,80,90,95]:\n",
    "    nn_pr_km = Neural_Network_PR_KM(neurons=300,batchsize=1,cluster=256,pre_weights=pre_trained_weights,pruning=i,pruning_method='out',stop_function=1,stop_parameter=2)\n",
    "    nn_pr_km.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_matrix(mat,percentage,method='out'):\n",
    "    threshold = (100-percentage)\n",
    "    \n",
    "    if method == 'inout':\n",
    "        threshold /= 4\n",
    "        perc_up,perc_down,perc_mid_up,perc_mid_down = 100 - threshold, threshold, 50 + threshold, 50 - threshold\n",
    "        percentile_up = np.percentile(mat,perc_up)\n",
    "        percentile_down = np.percentile(mat,perc_down)\n",
    "        percentile_mid_up = np.percentile(mat,perc_mid_up)\n",
    "        percentile_mid_down = np.percentile(mat,perc_mid_down)\n",
    "    else:\n",
    "        threshold /= 2\n",
    "        if method == 'in': perc_up, perc_down = 50 + threshold, 50 - threshold\n",
    "        elif method == 'out': perc_up, perc_down = 100 - threshold, threshold\n",
    "        percentile_up = np.percentile(mat,perc_up)\n",
    "        percentile_down = np.percentile(mat,perc_down)\n",
    "        \n",
    "    w_pruned = np.copy(mat)\n",
    "    for i,row in enumerate(mat):\n",
    "        for j,_ in enumerate(row):\n",
    "            if method == 'in':\n",
    "                if mat[i,j] > percentile_down and mat[i,j] < percentile_up:\n",
    "                    w_pruned[i,j] = 0\n",
    "            elif method == 'out':\n",
    "                if mat[i,j] < percentile_down or mat[i,j] > percentile_up:\n",
    "                    w_pruned[i,j] = 0\n",
    "            elif method == 'inout':\n",
    "                if mat[i,j] < percentile_down or mat[i,j] > percentile_up or (mat[i,j] > percentile_mid_down and mat[i,j] < percentile_mid_up):\n",
    "                    w_pruned[i,j] = 0\n",
    "    return w_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK with PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_PR:\n",
    "    \n",
    "    def __init__(self, neurons, batchsize, stop_function, stop_parameter, weights=None, pruning=None, pruning_method=None):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.pre_trained_weights = weights\n",
    "        self.pruning = pruning\n",
    "        self.pruning_method = pruning_method\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        \n",
    "        if weights == None:\n",
    "            # Standardize random weights\n",
    "            np.random.seed(RANDOM_SEED)\n",
    "            hidden_layer = np.random.rand(self.neurons, self.input_size + 1) / self.neurons\n",
    "            output_layer = np.random.rand(self.output_size, self.neurons + 1) / self.output_size\n",
    "            self.layers = [hidden_layer, output_layer]\n",
    "        else:\n",
    "            # Pruning weights\n",
    "            pw_hidden = pruning_matrix(pre_trained_weights[0],self.pruning,self.pruning_method)\n",
    "            pw_output = pruning_matrix(pre_trained_weights[1],self.pruning,self.pruning_method)\n",
    "            self.layers = [pw_hidden, pw_output]\n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nBatch Train: %d (%d%%)\\nBatch Test: %d (%d%%)\\nPruning: %d%% (%s)\\n%s\\n' % (self.neurons,len_batch_train,self.batchsize*100,len_batch_test,self.batchsize*100,self.pruning,self.pruning_method,typeTrainingPrint))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "\n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backpropagate(input_vector, target_vector)\n",
    "            \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        # Print last epoch\n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target):\n",
    "        c = 1./math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], 300, 1).T, output_deltas)\n",
    "        self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "\n",
    "    def accu(self, testing):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-11-22 18:02:58.059421) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000 (100%)\n",
      "Batch Test: 10000 (100%)\n",
      "Pruning: 50% (in)\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (39s)    Accuracy: 96.52%\tMin: 93.63% (8)\n",
      "Epoch 010 (6m42s)  Accuracy: 97.09%\tMin: 95.54% (9)\n",
      "\n",
      "-- Training Session End (2018-11-22 18:09:40.601668) --\n"
     ]
    }
   ],
   "source": [
    "pre_trained_weights = nn.getWeights()\n",
    "nn_pr = Neural_Network_PR(neurons=300,batchsize=1,weights=pre_trained_weights,pruning=50,pruning_method='in',stop_function=1,stop_parameter=2)\n",
    "nn_pr.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116eea0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments_in = get_data_from_json('experiments/Pruning_KM_Inner.json')\n",
    "experiments_out = get_data_from_json('experiments/Pruning_KM_Outer.json')\n",
    "experiments_inout = get_data_from_json('experiments/Pruning_KM_InnerOuter.json') \n",
    "\n",
    "p = [int(e['connection'] * 100) for e in experiments_in['data']]\n",
    "a_in = [e['accuracy'] * 100 for e in experiments_in['data']]\n",
    "a_out = [e['accuracy'] * 100 for e in experiments_out['data']]\n",
    "a_inout = [e['accuracy'] * 100 for e in experiments_inout['data']]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "w = 1.4\n",
    "r1 = plt.bar(np.array(p)-w,a_out,width=w,label='Outer Pruning')\n",
    "r2 = plt.bar(p,a_in,width=w,label='Inner Pruning')\n",
    "r3= plt.bar(np.array(p)+w,a_inout,width=w,label='Inner and outer Pruning')\n",
    "plt.axis([45, 100, 0, 135])\n",
    "plt.xticks(p_out)\n",
    "plt.yticks([0,20,40,60,80,100])\n",
    "for rects in [r1,r2,r3]:\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2.,height+1,'%d' % int(height),ha='center',va='bottom')\n",
    "plt.xlabel('Pruning %')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('RETRAINED NETWORK WITH PRUNING AND CLUSTERING')\n",
    "plt.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "plt.savefig('../../Pruning_Clustering.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a32dd6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments_in = get_data_from_json('experiments/Pruning_Inner.json')\n",
    "experiments_out = get_data_from_json('experiments/Pruning_Outer.json')\n",
    "experiments_inout = get_data_from_json('experiments/Pruning_InnerOuter.json') \n",
    "\n",
    "p = [int(e['connection'] * 100) for e in experiments_in['data']]\n",
    "a_in = [e['accuracy'] * 100 for e in experiments_in['data']]\n",
    "a_out = [e['accuracy'] * 100 for e in experiments_out['data']]\n",
    "a_inout = [e['accuracy'] * 100 for e in experiments_inout['data']]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "w = 1.4\n",
    "r1 = plt.bar(np.array(p)-w,a_out,width=w,label='Outer Pruning')\n",
    "r2 = plt.bar(p,a_in,width=w,label='Inner Pruning')\n",
    "r3= plt.bar(np.array(p)+w,a_inout,width=w,label='Inner and outer Pruning')\n",
    "plt.axis([45, 100, 0, 135])\n",
    "plt.xticks(p_out)\n",
    "plt.yticks([0,20,40,60,80,100])\n",
    "for rects in [r1,r2,r3]:\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2.,height+1,'%d' % int(height),ha='center',va='bottom')\n",
    "plt.xlabel('Pruning %')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.title('RETRAINED NETWORK WITH PRUNING')\n",
    "plt.legend(loc='upper right', shadow=True, fontsize='x-large')\n",
    "plt.savefig('../../Pruning_Result.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 2, 2]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "[a[3]] + a[:2] + [a[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[[[[[[]]]]]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
