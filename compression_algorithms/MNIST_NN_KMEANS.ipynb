{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST NEURAL NWTWORK WITH K-MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Settings (import and variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import struct\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import pairwise_distances_argmin_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN_NAME = 'train-images.idx3-ubyte'\n",
    "LABELS_TRAIN_NAME = 'train-labels.idx1-ubyte'\n",
    "IMAGES_TEST_NAME = 't10k-images.idx3-ubyte'\n",
    "LABELS_TEST_NAME = 't10k-labels.idx1-ubyte'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Functions for Loading and Showig Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    def wrap(*args):\n",
    "        time1 = time.time()\n",
    "        ret = f(*args)\n",
    "        time2 = time.time()\n",
    "        print('%s function took %0.2f ms' % (f.__name__, (time2-time1)*1000.0))\n",
    "        return ret\n",
    "    return wrap\n",
    "\n",
    "def load_data(one_hot=True, reshape=None, validation_size=10000):\n",
    "    x_tr = load_images(DATA_PATH+IMAGES_TRAIN_NAME)\n",
    "    y_tr = load_labels(DATA_PATH+LABELS_TRAIN_NAME)\n",
    "    x_te = load_images(DATA_PATH+IMAGES_TEST_NAME)\n",
    "    y_te = load_labels(DATA_PATH+LABELS_TEST_NAME)\n",
    "\n",
    "    x_tr = x_tr[:-validation_size]\n",
    "    y_tr = y_tr[:-validation_size]\n",
    "\n",
    "    if one_hot:\n",
    "        y_tr, y_te = [to_one_hot(y) for y in (y_tr, y_te)]\n",
    "\n",
    "    if reshape:\n",
    "        x_tr, x_te = [x.reshape(*reshape) for x in (x_tr, x_te)]\n",
    "\n",
    "    return x_tr, y_tr, x_te, y_te\n",
    "\n",
    "def load_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    return data.reshape(-1, 28 * 28) / np.float32(256)\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data\n",
    "\n",
    "def to_one_hot(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEVCAYAAAAvoDOaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAELZJREFUeJzt3X+wVOV9x/H3RwS1CFHLBSkaSJSk/pgG4q2hWi1OmozGULQdfzCWoLUhf2gnztD6sx3pjE5Nxpj4R2oGgRGrIaGNVjsyJAqxJp0J9UJQSSlqydXA5cel2slliljk2z/2XL1e755dds/uWXw+rxlmz57nnD3fe4bPfc6eZ+8+igjMLD1HlV2AmZXD4TdLlMNvliiH3yxRDr9Zohx+s0Q5/FYXSY9ICkmvFvBap2evFZL+tIj67PA5/A2S1DvkP3C1f4s7oM7tWS3PlF1LESQdXeOcfyh+znY4uuwCjmA/B3Zly6cAU7LlTcCBbHl7tZ0ljYmIt1tX3odWAOuHrRsDzMyWd7a3nCOXe/4GRcTlETErImYBS4c0vbs+IpZK+sMhvdL1kv5V0lvAQkl/PqTtFKh+SSzpk5JWSdoj6W1JL0taJEnN/iySVkp6RdJA9tq9kr4laVyV7f9E0lZJb0l6TtIZw9ovlvRs9nr7Jf1M0qV11DF4lbK02jYR8c6Q8zt4/h8Yssn99f7cqXP42+vvgTOBX1Lpweoi6RNUersrqFyt/SdwGnAvcF8BdV0OnAj8F/ArYCrwVWDJCNtOAf4BOAiMAi4AVksak9V6NbAa+APgTWAH8BngXyRdVkCt7yPpKOAvs6drI6Kn6GN8WDn87fUT4JSIOAP4zmHs99fAR4AtwEcj4neAP8va/kLSbzVZ16yImBARMyLiNOBr2fo/Hgz1EMcCX4iIs4B52bppwFXZ8tcBAQ8DUyPidOChbN3f1ajjVWArh3fpfhnwiWz5a3kb2vv5PX97fSciDkDl8vUwrtg/kz2eAQwM228U8LvAE03U9TlJj1C5mjh2yPoxwG/y/jDuiYhns+XHqFwBHA2cLWkycGrW9iXgS8Nq/W1JH6lWRETMbqD2v8oefx4RTzewf7Ic/vbaNez50Ev/UdnjSOEYTNBeKpfmw73VaEGSFlDprQH6qNyknAB8fFhddb3ckOVtQP8I2wy/kmiYpAuBWdlT9/qHyeEv154hy6cBr1F5/z3cvwPTgX3AFyNiL0DWi86NiB/WcayjJB07bN3bvBee/wGmRcT/SXqQ98I/3ERJF0bEc1QuuQf/D22OiD5J26mMfrwAXBkRB7NapwKfioj+ar2/pGeBk4F/jIi/qeNnuiV73Ab8Ux3b2xAOf7l+Bvwv8BvAKklbgN8bYbu7gT+i8t76dUlbgROohGzw/XUtFwH7h62bD7yYLZ8A/FLS24x89THoLWCNpG3AJ7N1rwGrsuVbgUeo/BLbJel1KoGeDKwFnsx57dOp3FCcXOuHkXQWcEn29N6IeKfWPvZ+vuFXoojop3LT7GVgLJUgzx9huy1U3vevotL7n0Xl8vnHwE1NlrGEyvDYfwPjgHXA3+ZsvyOrcTRwCPg34NIh9zIeBS7NahtDZXRjP/B9ihmZGHQzlfPVT+WGoh0m+Zt8zNLknt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5aotn6N14QJE2LatGntPKRZUnp7e9m7d29dXwvdVPglXUzlK6BGAUsj4p687adNm0ZPj+dUMGuV7u7uurdt+LJf0ijg21S+RPFMYJ6kMxt9PTNrr2be858LvBoR27IJJ78HzC2mLDNrtWbCP4XKvG6DtvPeTLXvkrRQUo+knv7+keZwMLMyNBP+kW4qfOCrgCNiSUR0R0R3V1dXE4czsyI1E/7tvDcvG1QmkOhrrhwza5dmwv88MF3Sx7KZXK8mfzYWM+sgDQ/1RcRBSTcCP6Qy1Lc8In5RWGVm1lJNjfNHxGpgdUG1mFkb+eO9Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFFNTdEtqRcYAN4BDkZEdxFFmVnrNRX+zEURsbeA1zGzNvJlv1mimg1/AD+StEHSwpE2kLRQUo+knv7+/iYPZ2ZFaTb850fEp4FLgBskXTh8g4hYEhHdEdHd1dXV5OHMrChNhT8i+rLHPcDjwLlFFGVmrddw+CWNlTRucBn4PLC5qMLMrLWauds/CXhc0uDrfDci1hRSlZm1XMPhj4htwKcKrMXM2shDfWaJcvjNEuXwmyXK4TdLlMNvlqgi/rDHPsT27duX275mTf7o7ooVK6q2vfDCC7n7bt6c/7GR8ePH57ZbPvf8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miPM7/ITAwMFC1bd26dbn7Ll26NLf9qaeeaqimeowdOza3ffTo0S07trnnN0uWw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5XH+DrBz587c9rvvvju3fdmyZVXbDhw4kLvv9OnTc9sXL16c237w4MHc9rvuuqtq21VXXZW773HHHZfbbs1xz2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrj/AXYunVrbvucOXNy23fs2JHbvn///tz22267rWrbddddl7vv1KlTc9tr/U19X19fbnveOP/MmTNz97XWqtnzS1ouaY+kzUPWnSTpaUmvZI8ntrZMMytaPZf9DwEXD1t3K7A2IqYDa7PnZnYEqRn+iHgOeGPY6rnA4DxMK4DLCq7LzFqs0Rt+kyJiJ0D2OLHahpIWSuqR1NPf39/g4cysaC2/2x8RSyKiOyK6u7q6Wn04M6tTo+HfLWkyQPa4p7iSzKwdGg3/k8CCbHkB8EQx5ZhZu9Qc55e0EpgNTJC0HbgTuAdYJel64HXgilYW2enefPPN3PYLLrggt/3444/PbZ8/f35u+znnnFO1TVLuvmWq9XNba9UMf0TMq9L02YJrMbM28sd7zRLl8JslyuE3S5TDb5Yoh98sUf6T3gLMmjWrqfYj2c0339zwvrW+uttayz2/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoj/NbU3p7e8suwRrknt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TH+a2lLrrooqptxxxzTBsrseHc85slyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiapniu7lwBeBPRFxdrZuMfBloD/b7PaIWN2qIq08AwMDue0bNmzIbb/22murtnXy9OEpqKfnfwi4eIT134yIGdk/B9/sCFMz/BHxHPBGG2oxszZq5j3/jZJelLRc0omFVWRmbdFo+B8ATgNmADuBb1TbUNJCST2Sevr7+6ttZmZt1lD4I2J3RLwTEYeAB4Fzc7ZdEhHdEdHd1dXVaJ1mVrCGwi9p8pCnlwObiynHzNqlnqG+lcBsYIKk7cCdwGxJM4AAeoGvtLBGM2uBmuGPiHkjrF7WglqsA61bty63/cCBA7ntixYtKrIcK5A/4WeWKIffLFEOv1miHH6zRDn8Zoly+M0S5a/utlzPPPNMbvtRR+X3HxMnTiyyHCuQe36zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEe57dcfX19ue3nnXdebvv48eOLLMcK5J7fLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcrhN0tUzb/nl3Qq8DBwMnAIWBIR90s6Cfg+MA3oBa6MiDdbV6q1Qq0pttesWZPbPmfOnCLLsTaqp+c/CCyKiDOAWcANks4EbgXWRsR0YG323MyOEDXDHxE7I2JjtjwAbAGmAHOBFdlmK4DLWlWkmRXvsN7zS5oGzATWA5MiYidUfkEAnpfJ7AhSd/glHQ/8ALgpIn59GPstlNQjqae/v7+RGs2sBeoKv6TRVIL/aEQ8lq3eLWly1j4Z2DPSvhGxJCK6I6K7q6uriJrNrAA1wy9JwDJgS0TcN6TpSWBBtrwAeKL48sysVer56u7zgfnAS5I2ZetuB+4BVkm6HngduKI1JVorrV+/Prd9//79ue233HJLkeVYG9UMf0T8FFCV5s8WW46ZtYs/4WeWKIffLFEOv1miHH6zRDn8Zoly+M0S5Sm6E7dixYraG+WYNGlSQZVYu7nnN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5XF+y3XCCSfkto8bN65NlVjR3PObJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8ZonyOH/iNm7cmNtea5Ylj/MfudzzmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJqjnOL+lU4GHgZOAQsCQi7pe0GPgy0J9tentErG5VodaYlStX5rZv2rQpt/2OO+4oshzrIPV8yOcgsCgiNkoaB2yQ9HTW9s2IuLd15ZlZq9QMf0TsBHZmywOStgBTWl2YmbXWYb3nlzQNmAmsz1bdKOlFScslnVhln4WSeiT19Pf3j7SJmZWg7vBLOh74AXBTRPwaeAA4DZhB5crgGyPtFxFLIqI7IrprfU7czNqnrvBLGk0l+I9GxGMAEbE7It6JiEPAg8C5rSvTzIpWM/ySBCwDtkTEfUPWTx6y2eXA5uLLM7NWqedu//nAfOAlSYPjQrcD8yTNAALoBb7SkgqtKbt27Wpq/2uuuaagSqzT1HO3/6eARmjymL7ZEcyf8DNLlMNvliiH3yxRDr9Zohx+s0Q5/GaJUkS07WDd3d3R09PTtuOZpaa7u5uenp6RhuY/wD2/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5aoto7zS+oHXhuyagKwt20FHJ5Ora1T6wLX1qgia5saEXV9X15bw/+Bg0s9EdFdWgE5OrW2Tq0LXFujyqrNl/1miXL4zRJVdviXlHz8PJ1aW6fWBa6tUaXUVup7fjMrT9k9v5mVpJTwS7pY0lZJr0q6tYwaqpHUK+klSZsklfr3x9k0aHskbR6y7iRJT0t6JXsccZq0kmpbLGlHdu42SfpCSbWdKunHkrZI+oWkr2brSz13OXWVct7aftkvaRTwMvA5YDvwPDAvIv6jrYVUIakX6I6I0seEJV0I7AMejoizs3VfB96IiHuyX5wnRsQtHVLbYmBf2TM3ZxPKTB46szRwGXAtJZ67nLqupITzVkbPfy7wakRsi4i3ge8Bc0uoo+NFxHPAG8NWzwVWZMsrqPznabsqtXWEiNgZERuz5QFgcGbpUs9dTl2lKCP8U4BfDXm+nc6a8juAH0naIGlh2cWMYFI2bfrg9OkTS65nuJozN7fTsJmlO+bcNTLjddHKCP9IXzHUSUMO50fEp4FLgBuyy1urT10zN7fLCDNLd4RGZ7wuWhnh3w6cOuT5KUBfCXWMKCL6ssc9wON03uzDuwcnSc0e95Rcz7s6aebmkWaWpgPOXSfNeF1G+J8Hpkv6mKQxwNXAkyXU8QGSxmY3YpA0Fvg8nTf78JPAgmx5AfBEibW8T6fM3FxtZmlKPnedNuN1KR/yyYYyvgWMApZHxN1tL2IEkj5OpbeHyiSm3y2zNkkrgdlU/uprN3An8M/AKuCjwOvAFRHR9htvVWqbTeXS9d2ZmwffY7e5tt8HfgK8BBzKVt9O5f11aecup655lHDe/Ak/s0T5E35miXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNE/T/UX79gtoulLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbe8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_digit(images,labels,idx):\n",
    "    image = np.array_split((images[idx] * 255).astype(np.uint8),28)\n",
    "    fig = pyplot.figure()\n",
    "    title = 'True Label: '+str(np.where(labels[idx] == 1.)[0][0])\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()\n",
    "    \n",
    "trX, trY, teX, teY = load_data()\n",
    "show_digit(trX,trY,42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "\n",
    "    def __init__(self, neurons=64, features=50, classes=10, epochs=50, learning_rate=0.1, batches=20, random_seed=None, train_img=None, train_lbl=None, test_img=None, test_lbl=None):\n",
    "        if random_seed:\n",
    "            self.random_seed = np.random.seed(random_seed)\n",
    "        self.weights = [np.random.randn(*w) * 0.1 for w in [(features, neurons), (neurons, classes)]]\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batches = batches\n",
    "        self.trX = train_img\n",
    "        self.trY = train_lbl\n",
    "        self.teX = test_img\n",
    "        self.teY = test_lbl\n",
    "    \n",
    "    def _feed_forward(self, X, weights):\n",
    "        a = [X]\n",
    "        for w in weights:\n",
    "            a.append(np.maximum(a[-1].dot(w),0))\n",
    "        return a\n",
    "\n",
    "    def _grads(self, X, Y, weights):\n",
    "        grads = np.empty_like(weights)\n",
    "        a = self._feed_forward(X, weights)\n",
    "        delta = a[-1] - Y\n",
    "        grads[-1] = a[-2].T.dot(delta)\n",
    "        for i in range(len(a)-2, 0, -1):\n",
    "            delta = (a[i] > 0) * delta.dot(weights[i].T)\n",
    "            grads[i-1] = a[i-1].T.dot(delta)\n",
    "        return grads / len(X)\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        print('\\nEpochs: %d\\nLearning Rate: %.3f\\nBatches Size: %d\\n' % (self.epochs,self.learning_rate,self.batches))\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            for j in range(0, len(self.trX), self.batches):\n",
    "                X, Y = self.trX[j:j+self.batches], self.trY[j:j+self.batches]\n",
    "                self.weights -= self.learning_rate * self._grads(X, Y, self.weights)\n",
    "            prediction = np.argmax(self._feed_forward(self.teX, self.weights)[-1], axis=1)\n",
    "\n",
    "            if i == 0 or (i+1) % 10 == 0:\n",
    "                diff = dt.datetime.now() - self.start_time\n",
    "                eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "                accuracy = np.mean(prediction == np.argmax(teY, axis=1))\n",
    "                epoch4print = str(i+1).zfill(len(str(self.epochs)))\n",
    "                print('Epoch %s: accuracy %f in %dm%ds' % ((epoch4print),accuracy,eta[0],eta[1]))\n",
    "                \n",
    "        print('\\nResult: %f in %dm%ds\\n' % (accuracy,eta[0],eta[1]))\n",
    "        print('-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-05-16 19:45:48.464853) --\n",
      "\n",
      "Epochs: 100\n",
      "Learning Rate: 0.001\n",
      "Batches Size: 25\n",
      "\n",
      "Epoch 001: accuracy 0.630200 in 0m1s\n",
      "Epoch 010: accuracy 0.879500 in 0m13s\n",
      "Epoch 020: accuracy 0.908400 in 0m26s\n",
      "Epoch 030: accuracy 0.920100 in 0m39s\n",
      "Epoch 040: accuracy 0.928100 in 0m52s\n",
      "Epoch 050: accuracy 0.933500 in 1m5s\n",
      "Epoch 060: accuracy 0.937100 in 1m18s\n",
      "Epoch 070: accuracy 0.941200 in 1m31s\n",
      "Epoch 080: accuracy 0.944000 in 1m45s\n",
      "Epoch 090: accuracy 0.946100 in 1m58s\n",
      "Epoch 100: accuracy 0.947600 in 2m11s\n",
      "\n",
      "Result: 0.947600 in 2m11s\n",
      "\n",
      "-- Training Session End (2018-05-16 19:47:59.714412) --\n"
     ]
    }
   ],
   "source": [
    "nn = Neural_Network(neurons=100,\n",
    "                    epochs=100,\n",
    "                    learning_rate=0.001,\n",
    "                    batches=25,\n",
    "                    features=N_FEATURES,\n",
    "                    classes=N_CLASSES,\n",
    "                    random_seed=RANDOM_SEED,\n",
    "                    train_img = trX,\n",
    "                    train_lbl = trY,\n",
    "                    test_img = teX,\n",
    "                    test_lbl = teY)\n",
    "\n",
    "nn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroid Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_centroid_index(centers,value):\n",
    "    centers = np.asarray(centers)\n",
    "    idx = (np.abs(centers - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def nearest_centroid(centers,value):\n",
    "    centers = np.asarray(centers)\n",
    "    idx = (np.abs(centers - value)).argmin()\n",
    "    return centers[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Layer Neural Network with K_MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_KMeans:\n",
    "\n",
    "    def __init__(self, neurons=64, features=50, classes=10, epochs=50, learning_rate=0.1, batches=20, k_means=None, random_seed=None, train_img=None, train_lbl=None, test_img=None, test_lbl=None):\n",
    "        if random_seed:\n",
    "            self.random_seed = np.random.seed(random_seed)\n",
    "        self.k_means = k_means\n",
    "        self.weights = [np.random.randn(*w) * 0.1 for w in [(features, neurons), (neurons, classes)]]\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batches = batches\n",
    "        self.trX = train_img\n",
    "        self.trY = train_lbl\n",
    "        self.teX = test_img\n",
    "        self.teY = test_lbl\n",
    "    \n",
    "    def _feed_forward(self, X, weights):\n",
    "        a = [X]\n",
    "        for w in weights:\n",
    "            a.append(np.maximum(a[-1].dot(w),0))\n",
    "        return a\n",
    "\n",
    "    def _grads(self, X, Y, weights):\n",
    "        grads = np.empty_like(weights)\n",
    "        a = self._feed_forward(X, weights)\n",
    "        delta = a[-1] - Y\n",
    "        grads[-1] = a[-2].T.dot(delta)\n",
    "        for i in range(len(a)-2, 0, -1):\n",
    "            delta = (a[i] > 0) * delta.dot(weights[i].T)\n",
    "            grads[i-1] = a[i-1].T.dot(delta)\n",
    "        return grads / len(X)\n",
    "    \n",
    "    def _redefine_weights(self,centers,weights):\n",
    "        for w in weights:\n",
    "            for i, row in enumerate(w):\n",
    "                for j, col in enumerate(row):\n",
    "                    w[i,j] = nearest_centroid(centers,w[i,j])\n",
    "        return weights\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        self.weights = self._redefine_weights(self.k_means.cluster_centers_,self.weights)\n",
    "        \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        print('\\nEpochs: %d\\nLearning Rate: %.3f\\nBatches Size: %d\\nClusters: %d\\n' % (self.epochs,self.learning_rate,self.batches,len(self.k_means.cluster_centers_)))\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            for j in range(0, len(self.trX), self.batches):\n",
    "                X, Y = self.trX[j:j+self.batches], self.trY[j:j+self.batches]\n",
    "                self.weights -= self.learning_rate * self._grads(X, Y, self.weights)\n",
    "            self.weights = self._redefine_weights(self.k_means.cluster_centers_,self.weights)\n",
    "            prediction = np.argmax(self._feed_forward(self.teX, self.weights)[-1], axis=1)\n",
    "\n",
    "            if i == 0 or (i+1) % 10 == 0:\n",
    "                diff = dt.datetime.now() - self.start_time\n",
    "                eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "                accuracy = np.mean(prediction == np.argmax(teY, axis=1))\n",
    "                epoch4print = str(i+1).zfill(len(str(self.epochs)))\n",
    "                print('Epoch %s: accuracy %f in %dm%ds' % ((epoch4print),accuracy,eta[0],eta[1]))\n",
    "                \n",
    "        print('\\nResult: %f in %dm%ds\\n' % (accuracy,eta[0],eta[1]))\n",
    "        print('-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=40, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CLUSTER = 40\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTER,random_state=RANDOM_SEED)\n",
    "nn_weights = nn.getWeights()\n",
    "weights_1D_array = np.append(np.hstack(nn_weights[0]),np.hstack(nn_weights[1]))\n",
    "kmeans.fit(weights_1D_array.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-05-16 19:48:10.327786) --\n",
      "\n",
      "Epochs: 50\n",
      "Learning Rate: 0.010\n",
      "Batches Size: 15\n",
      "Clusters: 40\n",
      "\n",
      "Epoch 01: accuracy 0.897200 in 0m2s\n",
      "Epoch 10: accuracy 0.941400 in 0m22s\n",
      "Epoch 20: accuracy 0.944500 in 0m43s\n",
      "Epoch 30: accuracy 0.944300 in 1m5s\n",
      "Epoch 40: accuracy 0.944600 in 1m27s\n",
      "Epoch 50: accuracy 0.944600 in 1m49s\n",
      "\n",
      "Result: 0.944600 in 1m49s\n",
      "\n",
      "-- Training Session End (2018-05-16 19:50:00.083291) --\n"
     ]
    }
   ],
   "source": [
    "nn_km = Neural_Network_KMeans(neurons=100,\n",
    "                              epochs=50,\n",
    "                              learning_rate=0.01,\n",
    "                              batches=15,\n",
    "                              features=N_FEATURES,\n",
    "                              classes=N_CLASSES,\n",
    "                              k_means = kmeans,\n",
    "                              random_seed=RANDOM_SEED,\n",
    "                              train_img = trX,\n",
    "                              train_lbl = trY,\n",
    "                              test_img = teX,\n",
    "                              test_lbl = teY)\n",
    "\n",
    "nn_km.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST FOR REPLACE WEIGHTS WITH INDEX IN CENTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_work function took 291.30 ms\n",
      "do_little function took 284.05 ms\n"
     ]
    }
   ],
   "source": [
    "def redefine_weights(centers,weights):\n",
    "        arr_ret = np.empty_like(weights)\n",
    "        for k,w in enumerate(weights):\n",
    "            arr_int = np.empty_like(w)\n",
    "            for i, row in enumerate(w):\n",
    "                for j, col in enumerate(row):\n",
    "                    arr_int[i,j] = nearest_centroid_index(centers,w[i,j])\n",
    "            arr_ret[k] = arr_int\n",
    "        return arr_ret\n",
    "\n",
    "@timing    \n",
    "def do_work():\n",
    "    a = [trX[1:15]]\n",
    "    for w in redefine_weights(kmeans.cluster_centers_,nn_weights):\n",
    "        w_list = [[kmeans.cluster_centers_[int(y)][0] for y in x] for x in w]\n",
    "        a.append(np.maximum(a[-1].dot(w_list),0))\n",
    "    return a\n",
    "\n",
    "@timing\n",
    "def do_little():\n",
    "    for w in redefine_weights(kmeans.cluster_centers_,nn_weights):\n",
    "        w_list = [[kmeans.cluster_centers_[int(y)][0] for y in x] for x in w]\n",
    "\n",
    "do_work()\n",
    "do_little()\n",
    "# FUNZIONAAAAAAAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
