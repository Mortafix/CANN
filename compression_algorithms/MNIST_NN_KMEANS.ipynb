{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK with K-MEANS for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "from random import randint\n",
    "from scipy import misc\n",
    "from scipy import special\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN = 'data_training'\n",
    "IMAGES_TEST = 'data_testing'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = DATA_PATH+IMAGES_TRAIN\n",
    "data_testing = DATA_PATH+IMAGES_TEST\n",
    "ft = gzip.open(data_training, 'rb')\n",
    "TRAINING = pickle.load(ft)\n",
    "ft.close()\n",
    "ft = gzip.open(data_testing, 'rb')\n",
    "TESTING = pickle.load(ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "\n",
    "    # Stop function\n",
    "    # 0 : Fixed (stop after n epochs)\n",
    "    # 1 : Progress (stop after n epochs w/o improvements)\n",
    "    # 2 : Std Dev (stop after an improvements below n)\n",
    "    \n",
    "    def __init__(self, neurons, batchsize, stop_function, stop_parameter):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        \n",
    "        # Standardize random weights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = np.random.rand(self.neurons, self.input_size + 1) / self.neurons\n",
    "        output_layer = np.random.rand(self.output_size, self.neurons + 1) / self.output_size\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "        self.iteration = 0\n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nBatch Train: %d\\nBatch Test: %d\\n%s\\n' % (self.neurons,len_batch_train,len_batch_test,typeTrainingPrint))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "\n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backpropagate(input_vector, target_vector)\n",
    "            \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        # Print last epoch\n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target):\n",
    "        c = 1./math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], 200, 1).T, output_deltas)\n",
    "        self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "\n",
    "    def accu(self, testing):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training Session Start (2018-10-17 18:10:20.489968) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 6000\n",
      "Batch Test: 1000\n",
      "Stop Function: 4 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (4s)     Accuracy: 47.75%\tMin: 00.0% (2)\n",
      "Epoch 010 (44s)    Accuracy: 91.81%\tMin: 80.94% (5)\n",
      "Epoch 020 (1m27s)  Accuracy: 92.4%\tMin: 82.03% (8)\n",
      "Epoch 027 (1m57s)  Accuracy: 93.22%\tMin: 88.79% (5)\n",
      "\n",
      "-- Training Session End (2018-10-17 18:12:18.002730) --\n"
     ]
    }
   ],
   "source": [
    "nn = Neural_Network(neurons=300,batchsize=0.1,stop_function=1,stop_parameter=4)\n",
    "nn.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find nearest centroid given a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_centroid_index(centers,value):\n",
    "    centers = np.asarray(centers)\n",
    "    idx = (np.abs(centers - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def nearest_centroid(centers,value):\n",
    "    centers = np.asarray(centers)\n",
    "    idx = (np.abs(centers - value)).argmin()\n",
    "    return centers[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building clusters with pre trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -0.0807723365637731,\n",
       " 1: 0.0030092386354939817,\n",
       " 2: 0.09926220110067807,\n",
       " 3: 0.5176137778670392,\n",
       " 4: -0.33514236687509735,\n",
       " 5: 0.3219722720677812,\n",
       " 6: -0.18941163326264426,\n",
       " 7: -0.4888695284396932,\n",
       " 8: 0.04637445574379022,\n",
       " 9: 0.18494851254956435}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_weights = nn.getWeights()\n",
    "\n",
    "def reshape_weights_for_kmeans(weights):\n",
    "    return np.hstack(weights).reshape(-1,1)\n",
    "\n",
    "def build_clusters(cluster,weights):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=cluster,random_state=RANDOM_SEED)\n",
    "    kmeans.fit(reshape_weights_for_kmeans(weights))\n",
    "    return {k:v[0] for k,v in enumerate(kmeans.cluster_centers_)}\n",
    "\n",
    "build_clusters(10,nn_weights[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redifine weights matrix for pre train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_weights(weights,centers):\n",
    "        arr_ret = np.empty_like(weights)\n",
    "        for i, row in enumerate(weights):\n",
    "            for j, col in enumerate(row):\n",
    "                arr_ret[i,j] = nearest_centroid_index(centers,weights[i,j])\n",
    "        return arr_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of distance between elements in centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_distance(weights,centroids):\n",
    "    tot = 0.\n",
    "    for i, row in enumerate(weights):\n",
    "        for j, col in enumerate(row):\n",
    "            weight = weights[i,j]\n",
    "            centroid = nearest_centroid(centroids,weight)[0]\n",
    "            tot += np.sqrt((weight - centroid)**2)\n",
    "    return tot / ((i+1)*(j+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean with different clusters number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean for 001 clusters 0.052564 (0m1s) \n",
      "Mean for 011 clusters 0.010691 (0m3s) \n",
      "Mean for 021 clusters 0.005886 (0m4s) \n",
      "Mean for 031 clusters 0.004236 (0m6s) \n",
      "Mean for 041 clusters 0.003233 (0m7s) \n",
      "Mean for 051 clusters 0.002900 (0m9s) \n",
      "Mean for 061 clusters 0.002431 (0m11s) \n",
      "Mean for 071 clusters 0.002411 (0m12s) \n",
      "Mean for 081 clusters 0.001846 (0m17s) \n",
      "Mean for 091 clusters 0.001732 (0m19s) \n",
      "Mean for 101 clusters 0.001684 (0m20s) \n"
     ]
    }
   ],
   "source": [
    "def find_clusters_number(values,n_from,n_to,n_jump):\n",
    "    start_time = dt.datetime.now()\n",
    "    RANDOM_SEED = 42\n",
    "    result = {}\n",
    "    for i in range(n_from,n_to+1,n_jump):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=i,random_state=RANDOM_SEED)\n",
    "        kmeans.fit(reshape_weights_for_kmeans(values))\n",
    "        mean = mean_distance(values,kmeans.cluster_centers_)\n",
    "        result[i] = mean\n",
    "        print(\"Mean for %s clusters %f (%s) \" % (str(i).zfill(3),mean,eta_from_start(start_time)))\n",
    "    return result\n",
    "\n",
    "def eta_from_start(start_time):\n",
    "    diff = dt.datetime.now() - start_time\n",
    "    eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "    return str(eta[0])+\"m\"+str(eta[1])+\"s\"\n",
    "        \n",
    "means_cluster_1_10 = find_clusters_number(nn_weights[0],1,101,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine matrix (index --> centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_from_dict(a,d):\n",
    "    new_array = np.copy(a)\n",
    "    for k, v in d.items():\n",
    "        new_array[a==k] = v\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate gradient for each cluster centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_gradient(idx_matrix,gradient,cluster):\n",
    "    return scipy.ndimage.sum(gradient,idx_matrix,index=range(cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a37fd53c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data_from_json(file):\n",
    "    with open(file) as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def get_list_values_from_json(data,field,variable):\n",
    "    return [element[field] for element in data[variable]]\n",
    "\n",
    "data = get_data_from_json('log/Log_Cluster_Setting_Mean.json')\n",
    "x = get_list_values_from_json(data,\"cluster\",\"cluster_mean\")\n",
    "y = get_list_values_from_json(data,\"mean\",\"cluster_mean\")\n",
    "\n",
    "plt.plot(x[:10],y[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Moris/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:1418: RuntimeWarning: init_size=300 should be larger than k=500. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    }
   ],
   "source": [
    "cluster_number = 500\n",
    "centers = build_clusters(cluster_number,nn_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map (i,j) -> k\n",
    "def dict_index_to_cluster(weights,centers):\n",
    "        dict_ret = {}\n",
    "        for i, row in enumerate(weights):\n",
    "            for j, col in enumerate(row):\n",
    "                dict_ret[(i,j)] = nearest_centroid_index([x for x in centers.values()],weights[i,j])\n",
    "        return dict_ret\n",
    "\n",
    "dict_index = dict_index_to_cluster(nn_weights[0],centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map k -> (i,j)\n",
    "def dict_cluster_to_index(dict_idx):\n",
    "    dict_ret = {}\n",
    "    for k,v in dict_idx.items():\n",
    "        if v in dict_ret:\n",
    "            dict_ret[v] += [k]\n",
    "        else:\n",
    "            dict_ret[v] = [k]\n",
    "    return dict_ret\n",
    "\n",
    "dict_cluster = dict_cluster_to_index(dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 125),\n",
       " (1, 360),\n",
       " (3, 215),\n",
       " (3, 244),\n",
       " (3, 381),\n",
       " (3, 463),\n",
       " (3, 604),\n",
       " (3, 627),\n",
       " (6, 404),\n",
       " (10, 653)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper function\n",
    "def getCluster(d,v):\n",
    "    return d[v]\n",
    "\n",
    "def getIndices(d,k):\n",
    "    return d[k]\n",
    "\n",
    "getCluster(dict_index,(7,42))\n",
    "getIndices(dict_cluster,106)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26862951e-03, 3.19190317e-03, 2.40046357e-03, ...,\n",
       "        8.20254009e-04, 1.20530890e-03, 1.08050035e-01],\n",
       "       [3.02574309e-03, 1.94675457e-03, 1.34426981e-03, ...,\n",
       "        2.65178764e-04, 2.04258203e-03, 6.86333198e-02],\n",
       "       [1.95085347e-03, 6.05894593e-04, 2.40046357e-03, ...,\n",
       "        2.04258203e-03, 2.92502098e-03, 4.88773534e-01],\n",
       "       ...,\n",
       "       [1.74872440e-03, 2.40046357e-03, 1.60996216e-03, ...,\n",
       "        3.02574309e-03, 1.06417056e-03, 1.39778088e-01],\n",
       "       [3.11801924e-03, 7.41992452e-05, 1.95085347e-03, ...,\n",
       "        3.27692829e-03, 4.95935282e-04, 1.88471897e-01],\n",
       "       [3.04695558e-03, 7.41992452e-05, 1.20530890e-03, ...,\n",
       "        1.80728862e-03, 3.11801924e-03, 2.48428515e-01]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dict (k -> (i,j)) to matrix with centers\n",
    "def dict_to_matrix(dict_index,dict_values,shape):\n",
    "    coord_array = np.asarray(list(dict_index.values()))\n",
    "    values_array = np.asarray(list(dict_values.values()))\n",
    "    return values_array[coord_array].reshape(shape)\n",
    "\n",
    "dict_to_matrix(dict_index,centers,(300,785))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26862951e-03, 3.19190317e-03, 2.40046357e-03, ...,\n",
       "        8.20254009e-04, 1.20530890e-03, 1.08050035e-01],\n",
       "       [3.02574309e-03, 1.94675457e-03, 1.34426981e-03, ...,\n",
       "        2.65178764e-04, 2.04258203e-03, 6.86333198e-02],\n",
       "       [1.95085347e-03, 6.05894593e-04, 2.40046357e-03, ...,\n",
       "        2.04258203e-03, 2.92502098e-03, 4.88773534e-01],\n",
       "       ...,\n",
       "       [1.74872440e-03, 2.40046357e-03, 1.60996216e-03, ...,\n",
       "        3.02574309e-03, 1.06417056e-03, 1.39778088e-01],\n",
       "       [3.11801924e-03, 7.41992452e-05, 1.95085347e-03, ...,\n",
       "        3.27692829e-03, 4.95935282e-04, 1.88471897e-01],\n",
       "       [3.04695558e-03, 7.41992452e-05, 1.20530890e-03, ...,\n",
       "        1.80728862e-03, 3.11801924e-03, 2.48428515e-01]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old function with index matrix\n",
    "idx_mat = redefine_weights(nn_weights[0],[v for v in centers.values()])\n",
    "values_from_dict(idx_mat,centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.3 ms ± 1.39 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "17 ms ± 560 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit values_from_dict(idx_mat,centers)\n",
    "%timeit dict_to_matrix(dict_index,centers,(300,785))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.9 ms ± 70.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit centroid_gradient(idx_mat,nn_weights[0],cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.5 ms ± 437 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def cg_4(K_Index,W_Matrix):\n",
    "    tmpindex = dict((key, ([x for x, _ in value], [y for _, y in value])) for key, value in K_Index.items())\n",
    "    return [W_Matrix[value[0],value[1]].sum() for value in tmpindex.values()]\n",
    "\n",
    "%timeit cg_4(dict_cluster,nn_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5 ms ± 717 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def dict_to_index_matrix(dict_cluster):\n",
    "    arr_ret = np.zeros((300,785))\n",
    "    for k,v in dict_cluster.items():\n",
    "        for i in v:\n",
    "            arr_ret[i] = k\n",
    "    return arr_ret\n",
    "\n",
    "%timeit idx_matrix = dict_to_index_matrix(dict_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_KM:\n",
    "\n",
    "    def __init__(self, neurons, batchsize, cluster, pre_weights, verbose, stop_function, stop_parameter):\n",
    "        \n",
    "        start_setting_time = dt.datetime.now()\n",
    "        \n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.batchsize = batchsize\n",
    "        self.verbose = verbose\n",
    "        self.cluster = cluster\n",
    "        self.iteration = 0\n",
    "        self.stop_f = stop_function\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        \n",
    "        # Variable for shape\n",
    "        shape_hidden = (self.neurons,self.input_size+1)\n",
    "        shape_output = (self.output_size,self.neurons+1)\n",
    "        self.layers_shape = [shape_hidden,shape_output]\n",
    "            \n",
    "        # Initialize cluster for pre-trained weights (dict with centers)\n",
    "        c_hidden = build_clusters(self.cluster,pre_weights[0])\n",
    "        c_output = build_clusters(self.cluster,pre_weights[-1])\n",
    "        self.centers = [c_hidden,c_output]\n",
    "        \n",
    "        # Initialize index matrix for pre-trained weights\n",
    "        idx_hidden = redefine_weights(pre_weights[0],list(c_hidden.values()))\n",
    "        idx_output = redefine_weights(pre_weights[-1],list(c_output.values()))\n",
    "        self.idx_layers = [idx_hidden,idx_output]\n",
    "        \n",
    "        # Initialize dict [map (i,j) -> k]\n",
    "        dict_hidden = dict_index_to_cluster(pre_weights[0],self.centers[0])\n",
    "        dict_output = dict_index_to_cluster(pre_weights[-1],self.centers[-1])\n",
    "        self.dict = [dict_hidden,dict_output]\n",
    "        \n",
    "        # Setting time print    \n",
    "        end_setting_time = dt.datetime.now() - start_setting_time\n",
    "        eta = divmod(end_setting_time.days * 86400 + end_setting_time.seconds, 60)\n",
    "        self.eta_print_setting = str(eta[0])+\"m\"+str(eta[1])+\"s\"\n",
    "        if self.verbose:\n",
    "            print(\"--- Setting Time: %s ---\" % self.eta_print_setting)\n",
    "    \n",
    " \n",
    "\n",
    "    def train(self, training, testing):\n",
    "        \n",
    "        accu = [0.,0.]\n",
    "        \n",
    "        # Batch Setting\n",
    "        len_batch_train = len(training[0])\n",
    "        len_batch_test = len(testing[0])\n",
    "        if(self.batchsize > 0 and self.batchsize <= 1):\n",
    "            len_batch_train = int(np.ceil(len_batch_train * self.batchsize))\n",
    "            len_batch_test = int(np.ceil(len_batch_test * self.batchsize))\n",
    "        \n",
    "        # Divide training and testing batches\n",
    "        test_output = testing[0:len_batch_test][0:len_batch_test]\n",
    "        inputs = training[0][0:len_batch_train]\n",
    "        targets = np.zeros((len_batch_train, 10))\n",
    "        for i in range(len_batch_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "        \n",
    "        # Start prints \n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('-- Training Session Start (%s) --' % (self.start_time))\n",
    "        typeTrainingPrint = \"Stop Function: \"    \n",
    "        if self.stop_f == 0:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epochs\"\n",
    "        elif self.stop_f == 1:\n",
    "            typeTrainingPrint += str(self.stop_p)+\" epoch(s) w/o improvements\"\n",
    "        elif self.stop_f == 2:\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print('\\nNeurons: %d\\nBatch Train: %d\\nBatch Test: %d\\n%s\\n' % (self.neurons,len_batch_train,len_batch_test,typeTrainingPrint))\n",
    "        \n",
    "        # Performs iterations\n",
    "        while not self.is_stop_function_enabled(accu[1]):\n",
    "            \n",
    "            # Backpropagate with feed forward\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                # from index matrix to weights matrix with centroid\n",
    "                weights = []\n",
    "                for d,c,s in zip(self.dict,self.centers,self.layers_shape):\n",
    "                    w = dict_to_matrix(d,c,s)\n",
    "                    #w = values_from_dict(idxm,c)\n",
    "                    weights.append(w)\n",
    "                self.backpropagate(input_vector, target_vector, weights)\n",
    "                \n",
    "            # Accuracy\n",
    "            accu = self.accu(test_output,weights)\n",
    "            self.iteration += 1\n",
    "            \n",
    "            # Messages\n",
    "            #if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "                      \n",
    "        # Print last epoch result\n",
    "        if self.iteration % 10 != 0:\n",
    "            self.print_message_iter(self.iteration,accu,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector, weights):\n",
    "        outputs = []\n",
    "        for w in weights:\n",
    "            input_with_bias = np.append(input_vector, 1)   # Ajout constante\n",
    "            output = np.inner(w, input_with_bias)\n",
    "            output = special.expit(output) # Sigmoid function\n",
    "            outputs.append(output)\n",
    "            # The output is the input of the next layer\n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backpropagate(self, input_vector, target, weights):\n",
    "        c = 0.1/math.sqrt(self.iteration + 10)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector, weights)\n",
    "\n",
    "        # Calculation of partial derivatives for the output layer and subtraction\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        gradient = np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        cg = centroid_gradient(self.idx_layers[-1],gradient,self.cluster)\n",
    "        self.centers[-1] = {x: self.centers[-1][x]-(c*cg[x]) for x in self.centers[-1]}\n",
    "\n",
    "        # Calculation of partial derivatives for the hidden layer and subtraction\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(weights[-1], 200, 1).T, output_deltas)\n",
    "        gradient = np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "        cg = centroid_gradient(self.idx_layers[0],gradient,self.cluster)\n",
    "        self.centers[0] = {x: self.centers[0][x]-(c*cg[x]) for x in self.centers[0]}\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self, input_vector, weights):\n",
    "        return self.feed_forward(input_vector,weights)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector, weights):\n",
    "        return np.argmax(self.feed_forward(input_vector,weights)[-1])\n",
    "\n",
    "    def accu(self, testing, weights):\n",
    "        res = np.zeros((10, 2))\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k], weights) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        each = [res[k][0]/res[k][1] for k in range(len(res))]\n",
    "        min_c = sorted(range(len(each)), key=lambda k: each[k])[0]\n",
    "        return np.round([each[min_c]*100, total[0]/total[1]*100, min_c], 2)\n",
    "    \n",
    "    \n",
    "    def is_stop_function_enabled(self,accuracy):\n",
    "        if self.stop_f == 0:\n",
    "            if self.iteration < self.stop_p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f == 1:\n",
    "            if accuracy > self.best or self.iteration == 0:\n",
    "                self.same = 0\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                self.same += 1\n",
    "                if self.same < self.stop_p:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "        elif self.stop_f == 2:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    def print_message_iter(self,iteration,accu,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy: '+str(accu[1]).zfill(4)+'%\\tMin: '+ str(accu[0]).zfill(4)+ '% ('+str(int(accu[2]))+')'\n",
    "        print(message)\n",
    "        \n",
    "    def getWeights(self):\n",
    "        return self.layers\n",
    "    \n",
    "    def minsec2sec(self,time):\n",
    "        if 'm' in time:\n",
    "            splitted = time.split('m')\n",
    "            return int(splitted[0]) * 60 + int(splitted[1][:-1])\n",
    "        else:\n",
    "            return int(time[:-1])\n",
    "    \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Moris/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py:1418: RuntimeWarning: init_size=300 should be larger than k=1000. Setting it to 3*k\n",
      "  init_size=init_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Setting Time: 0m40s ---\n",
      "-- Training Session Start (2018-10-16 13:51:06.430724) --\n",
      "\n",
      "Neurons: 300\n",
      "Batch Train: 60000\n",
      "Batch Test: 10000\n",
      "Stop Function: 2 epoch(s) w/o improvements\n",
      "\n",
      "Epoch 001 (39m8s)  Accuracy: 93.57%\tMin: 89.01% (5)\n",
      "Epoch 002 (78m3s)  Accuracy: 93.67%\tMin: 89.46% (5)\n",
      "Epoch 003 (115m24s) Accuracy: 93.88%\tMin: 89.8% (5)\n",
      "Epoch 004 (154m13s) Accuracy: 93.92%\tMin: 90.7% (5)\n",
      "Epoch 005 (193m1s) Accuracy: 93.92%\tMin: 91.59% (5)\n",
      "Epoch 006 (231m51s) Accuracy: 94.01%\tMin: 92.02% (7)\n",
      "Epoch 007 (268m55s) Accuracy: 94.1%\tMin: 92.17% (9)\n",
      "Epoch 008 (305m50s) Accuracy: 94.13%\tMin: 91.97% (9)\n",
      "Epoch 009 (343m56s) Accuracy: 94.21%\tMin: 91.67% (9)\n",
      "Epoch 010 (381m3s) Accuracy: 94.26%\tMin: 91.48% (9)\n",
      "Epoch 011 (419m42s) Accuracy: 94.28%\tMin: 91.38% (9)\n",
      "Epoch 012 (458m45s) Accuracy: 94.27%\tMin: 91.28% (9)\n",
      "Epoch 013 (495m37s) Accuracy: 94.29%\tMin: 91.08% (9)\n",
      "Epoch 014 (532m10s) Accuracy: 94.32%\tMin: 90.98% (9)\n",
      "Epoch 015 (576m6s) Accuracy: 94.37%\tMin: 90.88% (9)\n",
      "Epoch 016 (614m2s) Accuracy: 94.44%\tMin: 90.78% (9)\n",
      "Epoch 017 (650m29s) Accuracy: 94.47%\tMin: 90.88% (9)\n",
      "Epoch 018 (686m53s) Accuracy: 94.49%\tMin: 90.98% (9)\n",
      "Epoch 019 (723m20s) Accuracy: 94.48%\tMin: 90.98% (9)\n",
      "Epoch 020 (759m46s) Accuracy: 94.44%\tMin: 90.98% (9)\n",
      "\n",
      "-- Training Session End (2018-10-17 02:30:53.193160) --\n"
     ]
    }
   ],
   "source": [
    "nn_km = Neural_Network_KM(neurons=300,batchsize=1,cluster=1000,pre_weights=nn_weights,verbose=True,stop_function=1,stop_parameter=2)\n",
    "nn_km.train(TRAINING,TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
